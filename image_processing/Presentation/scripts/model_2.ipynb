{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files: 100\n",
      "Number of mask files: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 21:12:11.687573: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-09-01 21:12:11.687597: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-09-01 21:12:11.687607: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-09-01 21:12:11.687626: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-01 21:12:11.687640: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 21:12:14.928620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12s/step - accuracy: 0.6087 - loss: 0.7337 - val_accuracy: 0.0456 - val_loss: 14.9403 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 10s/step - accuracy: 0.9533 - loss: 0.2657 - val_accuracy: 0.0430 - val_loss: 15.1816 - learning_rate: 0.0010\n",
      "Epoch 3/100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Enable Mixed Precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Set up paths\n",
    "image_dir = '../images/training_images/'\n",
    "mask_dir = '../images/mask/'\n",
    "\n",
    "# Get file lists\n",
    "image_files = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir) \n",
    "                      if fname.lower().endswith(('.jpg', '.jpeg', '.jpe', '.jfif'))])\n",
    "mask_files = sorted([os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir)\n",
    "                     if fname.lower().endswith(('.jpg', '.jpeg', '.jpe', '.jfif'))])\n",
    "\n",
    "print(f\"Number of image files: {len(image_files)}\")\n",
    "print(f\"Number of mask files: {len(mask_files)}\")\n",
    "\n",
    "# Define data loading function\n",
    "def load_image_mask(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [512, 512])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_jpeg(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, [512, 512])\n",
    "    mask = tf.cast(mask, tf.float32) / 255.0\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "# Create dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_files, mask_files))\n",
    "dataset = dataset.map(lambda x, y: tf.py_function(load_image_mask, [x, y], [tf.float32, tf.float32]),\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.map(lambda x, y: (tf.ensure_shape(x, [512, 512, 3]), tf.ensure_shape(y, [512, 512, 1])))\n",
    "\n",
    "# Split dataset\n",
    "BUFFER_SIZE = len(image_files)\n",
    "dataset = dataset.shuffle(buffer_size=BUFFER_SIZE)\n",
    "train_size = int(0.8 * len(image_files))\n",
    "val_size = len(image_files) - train_size\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Set batch size\n",
    "BATCH_SIZE = 16  \n",
    "\n",
    "# Prepare datasets for training\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# Data Augmentation\n",
    "def augment(image, mask):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    mask = tf.image.random_flip_left_right(mask)\n",
    "    return image, mask\n",
    "\n",
    "train_dataset = train_dataset.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Define U-Net model\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model\n",
    "\n",
    "# Build and compile the model\n",
    "input_shape = (512, 512, 3)\n",
    "model = build_unet(input_shape)\n",
    "\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "epochs = 100  \n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save('final_model.keras')\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
