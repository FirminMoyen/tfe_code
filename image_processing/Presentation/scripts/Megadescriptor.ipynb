{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import timm\n",
    "import numpy as np\n",
    "from wildlife_tools.data import WildlifeDataset\n",
    "from wildlife_tools.features import DeepFeatures\n",
    "from wildlife_tools.similarity import CosineSimilarity\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare dataset\n",
    "image_folder = '../test/Building_images'\n",
    "print(os.listdir(image_folder))\n",
    "image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder)]\n",
    "\n",
    "# Create a DataFrame with correct column name 'path'\n",
    "metadata = pd.DataFrame({'path': image_paths})\n",
    "\n",
    "# Define enhanced transformations with data augmentation and black and white conversion\n",
    "transform = T.Compose([\n",
    "    T.Resize([384, 384]),\n",
    "    T.Grayscale(num_output_channels=3),\n",
    "    T.RandomRotation(10),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Add a dummy 'identity' column for compatibility\n",
    "metadata['identity'] = range(len(metadata))\n",
    "\n",
    "# Create the dataset\n",
    "dataset = WildlifeDataset(metadata, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MegaDescriptor-L-384 model\n",
    "model_name = 'hf-hub:BVRA/MegaDescriptor-L-384'\n",
    "extractor = DeepFeatures(timm.create_model(model_name, num_classes=0, pretrained=True))\n",
    "print(\"model loaded successfully\")\n",
    "\n",
    "# Extract features\n",
    "features = extractor(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity\n",
    "similarity_function = CosineSimilarity()\n",
    "similarity_dict = similarity_function(features, features)\n",
    "\n",
    "# Access the actual similarity values\n",
    "similarity_matrix = similarity_dict['cosine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top N similar images with similarity scores\n",
    "def get_top_n_similar_with_scores(similarity_matrix, n=5):\n",
    "    top_n_indices = np.argsort(-similarity_matrix, axis=1)[:, 1:n+1]\n",
    "    top_n_scores = -np.sort(-similarity_matrix, axis=1)[:, 1:n+1]\n",
    "    return top_n_indices, top_n_scores\n",
    "\n",
    "# Get top 5 similar images for each image\n",
    "top_5_similar, top_5_scores = get_top_n_similar_with_scores(similarity_matrix, n=5)\n",
    "\n",
    "# Display results with images and similarity scores\n",
    "for idx, (similar_indices, scores) in enumerate(zip(top_5_similar, top_5_scores)):\n",
    "    print(f\"Image {idx} ({os.path.basename(metadata['path'][idx])}) is similar to:\")\n",
    "    query_img = Image.open(metadata['path'][idx]).convert(\"L\").convert(\"RGB\").resize((384, 384))  # Convert to black and white and back to RGB\n",
    "    \n",
    "    # Create a new image for the results with more space\n",
    "    result_img = Image.new('RGB', (2340, 484 + 60), (255, 255, 255))  # Adjust width for spacing and height for text\n",
    "    \n",
    "    # Draw the query image details with background\n",
    "    draw = ImageDraw.Draw(result_img)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 40)  # Larger font size\n",
    "    draw.rectangle([(0, 0), (2340, 60)], fill=\"white\")\n",
    "    draw.text((10, 10), f\"Query Image: {os.path.basename(metadata['path'][idx])}\", fill=\"black\", font=font)\n",
    "    result_img.paste(query_img, (10, 70))  # Add padding\n",
    "    \n",
    "    for i, (similar_idx, score) in enumerate(zip(similar_indices, scores)):\n",
    "        similar_img = Image.open(metadata['path'][similar_idx]).convert(\"L\").convert(\"RGB\").resize((384, 384))  # Convert to black and white and back to RGB\n",
    "        result_img.paste(similar_img, ((i + 1) * 384 + 20 * (i + 1), 70))  # Add more spacing between images\n",
    "        draw.rectangle([((i + 1) * 384 + 20 * (i + 1), 0), ((i + 2) * 384 + 20 * (i + 1), 60)], fill=\"white\")\n",
    "        draw.text(((i + 1) * 384 + 20 * (i + 1) + 10, 10), f\"Similar Image: {os.path.basename(metadata['path'][similar_idx])}\\nConfidence: {score*100:.2f}%\", fill=\"black\", font=font)\n",
    "    \n",
    "    # Display the aggregated result image\n",
    "    plt.imshow(result_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
